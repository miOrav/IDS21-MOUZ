{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7352078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-ca121638a718>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  needed_data['Pawpularity'] = needed_data['Pawpularity'].astype(str)\n",
      "C:\\Users\\uzingel\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import locale\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "\n",
    "test_data = pd.read_csv('test.csv') \n",
    "train_data = pd.read_csv('train.csv') \n",
    "\n",
    "\n",
    "# input path for the images\n",
    "base_path = \"../IDS2021_HW09/\"\n",
    "\n",
    "\n",
    "#We select the necessary metadata and convert it into the necessary form\n",
    "needed_data = train_data[['Id', 'Pawpularity']]\n",
    "size = len(needed_data)\n",
    "needed_data['Pawpularity'] = needed_data['Pawpularity'].astype(str)\n",
    "i=0\n",
    "for expression in os.listdir(base_path + \"files/train/\"):\n",
    "    needed_data['Id'].iloc[i] = expression\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "#We load all the images into an array\n",
    "images = []\n",
    "for filename in needed_data['Id']:\n",
    "    image = cv2.imread(base_path + \"files/train/\" + filename)\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    images.append(image)\n",
    "\n",
    "    \n",
    "image_array = np.array(images)\n",
    "\n",
    "    \n",
    "#funtion to make the neural network\n",
    "def make_cnn_model(image_width, image_height, image_depth, filters=(16, 32, 64), regress=False):\n",
    "    Shape = (image_height, image_width, image_depth)\n",
    "    inputs = Input(shape=Shape)\n",
    "    for (i, f) in enumerate(filters):\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(20)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(8)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "image_array = image_array /255.0\n",
    "split = train_test_split(train_data['Pawpularity'], image_array, test_size=0.25, random_state=40)\n",
    "(train, test, trainImages, testImages) = split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0eaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(train_data['Pawpularity'], image_array, test_size=0.25, random_state=40)\n",
    "(train, test, trainImages, testImages) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c61457dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 616.1407 - val_loss: 141.7598\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 443.2402 - val_loss: 124.5618\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 368.3957 - val_loss: 105.0055\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 288.8895 - val_loss: 94.1747\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 220.0220 - val_loss: 90.8432\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 171.4921 - val_loss: 86.0182\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 144.7242 - val_loss: 76.2039\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 126.0893 - val_loss: 65.3121\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 111.5838 - val_loss: 59.8680\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 102.0447 - val_loss: 62.1813\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 95.0397 - val_loss: 75.8819\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 90.4124 - val_loss: 98.0754\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 86.2071 - val_loss: 128.5441\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 84.4396 - val_loss: 163.3830\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 78.5815 - val_loss: 196.3820\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 78.3891 - val_loss: 247.8292\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 72.1916 - val_loss: 286.3319\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 70.9620 - val_loss: 316.6736\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 69.5237 - val_loss: 364.8399\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 66.9690 - val_loss: 370.8727\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 65.5831 - val_loss: 400.8884\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 417s 52s/step - loss: 64.3954 - val_loss: 410.4608\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 30s 4s/step - loss: 62.6328 - val_loss: 486.9468\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 64.1576 - val_loss: 474.0452\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 61.6450 - val_loss: 461.4929\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 64.1486 - val_loss: 515.2336\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 62.2371 - val_loss: 414.1235\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 61.8192 - val_loss: 422.9324\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 60.0879 - val_loss: 432.0562\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 59.4551 - val_loss: 380.7936\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 60.8281 - val_loss: 326.8945\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 59.7967 - val_loss: 307.9008\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 57.8730 - val_loss: 310.1824\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 58.7014 - val_loss: 248.7583\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 57.9354 - val_loss: 229.9760\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 59.5133 - val_loss: 227.1334\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 55.5924 - val_loss: 193.9138\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 56.5834 - val_loss: 173.9424\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 57.9427 - val_loss: 137.7028\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 57.2637 - val_loss: 140.6022\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 57.7613 - val_loss: 111.1935\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 57.3852 - val_loss: 132.1450\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 60.1712 - val_loss: 161.0510\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 59.1126 - val_loss: 74.7571\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 58.1117 - val_loss: 62.6981\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 56.3326 - val_loss: 63.7997\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 55.6925 - val_loss: 67.1297\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 56.9330 - val_loss: 67.4743\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 55.2608 - val_loss: 62.2746\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 28s 3s/step - loss: 55.1939 - val_loss: 61.3453\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 54.3379 - val_loss: 62.3340\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 53.7147 - val_loss: 59.9007\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 54.6233 - val_loss: 60.9880\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 54.2678 - val_loss: 61.2243\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 53.1742 - val_loss: 59.2906\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 54.3445 - val_loss: 59.9568\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 53.4659 - val_loss: 60.8219\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 53.8254 - val_loss: 60.2132\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 51.7138 - val_loss: 59.6855\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 52.5093 - val_loss: 59.8034\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 52.7688 - val_loss: 60.9520\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 52.0679 - val_loss: 60.8072\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 52.0883 - val_loss: 59.8515\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 53.2937 - val_loss: 61.3799\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 51.6724 - val_loss: 60.6518\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 53.8213 - val_loss: 62.3858\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 52.0136 - val_loss: 63.4559\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 52.3521 - val_loss: 63.6606\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.8475 - val_loss: 62.5443\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 51.9421 - val_loss: 62.8213\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 51.4172 - val_loss: 63.1384\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.6629 - val_loss: 62.9464\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.3427 - val_loss: 62.2254\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.9633 - val_loss: 61.4514\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.5672 - val_loss: 61.8197\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.4302 - val_loss: 64.0438\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.6785 - val_loss: 64.3960\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.2144 - val_loss: 64.0280\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.8787 - val_loss: 63.9405\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 50.7223 - val_loss: 63.4724\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.8517 - val_loss: 64.2678\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 27s 3s/step - loss: 49.7041 - val_loss: 63.6092\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 48.3774 - val_loss: 63.6593\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.0980 - val_loss: 64.0486\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.7912 - val_loss: 64.2764\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.1345 - val_loss: 63.7229\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.4898 - val_loss: 61.1545\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 48.7382 - val_loss: 62.1817\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.3158 - val_loss: 62.3797\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.1814 - val_loss: 62.1885\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.2237 - val_loss: 62.1786\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.0717 - val_loss: 62.5200\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.3579 - val_loss: 61.2331\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 46.5967 - val_loss: 63.0994\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 49.5228 - val_loss: 65.1128\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.6924 - val_loss: 62.9100\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.6114 - val_loss: 62.1440\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.0397 - val_loss: 62.3626\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.8833 - val_loss: 63.0945\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 46.2563 - val_loss: 62.9859\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 46.7070 - val_loss: 61.9918\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.3393 - val_loss: 63.6158\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 46.2384 - val_loss: 62.4770\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.4924 - val_loss: 62.0133\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 48.6610 - val_loss: 63.2486\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.4112 - val_loss: 63.4057\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.5851 - val_loss: 63.4905\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.4432 - val_loss: 62.9598\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 47.0752 - val_loss: 62.5387\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.8675 - val_loss: 63.7125\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.2252 - val_loss: 63.5612\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 46.8455 - val_loss: 63.8529\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.8107 - val_loss: 60.4052\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.4384 - val_loss: 60.0561\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.8924 - val_loss: 61.9202\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.0767 - val_loss: 63.2980\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.4119 - val_loss: 61.1304\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.2888 - val_loss: 60.8767\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.4653 - val_loss: 63.0483\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.8841 - val_loss: 62.6787\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.2205 - val_loss: 62.0186\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.7730 - val_loss: 61.5605\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.1716 - val_loss: 61.8686\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 45.7727 - val_loss: 62.7954\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.8563 - val_loss: 61.5038\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.5682 - val_loss: 62.9452\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.5258 - val_loss: 63.3859\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.9631 - val_loss: 63.2592\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.6201 - val_loss: 64.2313\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 44.8095 - val_loss: 63.7397\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 45.3170 - val_loss: 62.9932\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.5708 - val_loss: 61.1549\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 43.6606 - val_loss: 62.4994\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.1675 - val_loss: 61.5993\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 44.3418 - val_loss: 64.0973\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 44.7066 - val_loss: 63.8273\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 43.7577 - val_loss: 64.7273\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 45.2928 - val_loss: 63.5822\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 42.7473 - val_loss: 63.2843\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 43.2009 - val_loss: 62.9700\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 43.8606 - val_loss: 63.2961\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 44.1045 - val_loss: 63.2027\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.8158 - val_loss: 61.8662\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 43.1662 - val_loss: 62.7596\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 43.3865 - val_loss: 63.7664\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.6716 - val_loss: 62.9574\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 44.1069 - val_loss: 63.9252\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 43.7325 - val_loss: 64.3655\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.4942 - val_loss: 64.8556\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 43.3977 - val_loss: 65.7633\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 44.2199 - val_loss: 65.6969\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.6516 - val_loss: 65.0136\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 43.2570 - val_loss: 65.4512\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.2327 - val_loss: 66.2333\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 41.5742 - val_loss: 66.0889\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.2848 - val_loss: 65.5208\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.4554 - val_loss: 65.2203\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 43.0694 - val_loss: 68.2582\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 41.9476 - val_loss: 66.2582\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 43.3910 - val_loss: 64.0323\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.3769 - val_loss: 64.4200\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.3450 - val_loss: 65.0445\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 27s 3s/step - loss: 42.4356 - val_loss: 67.1805\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.8690 - val_loss: 64.9913\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 43.2433 - val_loss: 61.5701\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 43.3899 - val_loss: 62.1207\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.3612 - val_loss: 61.3799\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 41.9150 - val_loss: 62.8598\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 41.4972 - val_loss: 63.0483\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.9213 - val_loss: 63.6697\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 40.8523 - val_loss: 63.3599\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 41.7173 - val_loss: 65.7447\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 41.9728 - val_loss: 65.6682\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 41.7723 - val_loss: 62.3227\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 40.7381 - val_loss: 64.8528\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.0675 - val_loss: 60.6067\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.7122 - val_loss: 61.2115\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 40.7231 - val_loss: 63.5056\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.3213 - val_loss: 60.0397\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 40.7109 - val_loss: 62.6002\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 42.3633 - val_loss: 62.4367\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 42.8413 - val_loss: 62.3615\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 40.9365 - val_loss: 65.3887\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 40.7243 - val_loss: 64.0459\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 41.0789 - val_loss: 63.5514\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 40.0635 - val_loss: 63.9923\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 41.1021 - val_loss: 62.8571\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 39.6454 - val_loss: 64.3264\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 26s 3s/step - loss: 41.1181 - val_loss: 60.2966\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 27s 3s/step - loss: 41.2870 - val_loss: 60.5456\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 31s 4s/step - loss: 40.6123 - val_loss: 64.4070\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 39.3049 - val_loss: 60.9971\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 40.1513 - val_loss: 62.3555\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 40.4170 - val_loss: 63.3089\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 41.2385 - val_loss: 61.9494\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 40.8205 - val_loss: 61.0554\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 28s 3s/step - loss: 40.2672 - val_loss: 62.4128\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 41.0564 - val_loss: 62.5488\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 29s 4s/step - loss: 40.3791 - val_loss: 65.1873\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 28s 4s/step - loss: 41.3844 - val_loss: 62.1139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27532182580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We convert the pawpularity to be between [0,1]\n",
    "maxPrice = train.max()\n",
    "trainY = train / maxPrice\n",
    "testY = test / maxPrice\n",
    "#We make and train the model\n",
    "model2 = make_cnn_model(64, 64, 3, regress=True)\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model2.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "\n",
    "print(\"[INFO] training model...\")\n",
    "model2.fit(x=trainImages, y=trainY, \n",
    "    validation_data=(testImages, testY),\n",
    "    epochs=200, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65aed5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.113909339476976\n",
      "[[0.22978726]\n",
      " [0.283046  ]\n",
      " [0.30846784]\n",
      " ...\n",
      " [0.21248013]\n",
      " [0.29881638]\n",
      " [0.3078935 ]]\n",
      "759     0.29\n",
      "5719    0.38\n",
      "7291    0.39\n",
      "2643    0.84\n",
      "4072    0.04\n",
      "        ... \n",
      "6508    0.28\n",
      "3026    0.30\n",
      "1937    0.15\n",
      "6421    0.29\n",
      "6411    0.27\n",
      "Name: Pawpularity, Length: 2478, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Predict the values of images\n",
    "preds = model2.predict(testImages)\n",
    "\n",
    "#Calculate the differences between results and the real values\n",
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "\n",
    "#Calculate the mean of our prediction accuracy\n",
    "mean = np.mean(absPercentDiff)\n",
    "print(mean)\n",
    "print(preds)\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57444ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the values for the test data\n",
    "\n",
    "needed_data_test = test_data\n",
    "j = 0\n",
    "for expression in os.listdir(base_path + \"test/\"):\n",
    "    needed_data_test['Id'].iloc[j] = expression\n",
    "    j+=1\n",
    "\n",
    "\n",
    "images2 = []\n",
    "for filename in needed_data_test['Id']:\n",
    "    image2 = cv2.imread(base_path + \"test/\" + filename)\n",
    "    image2 = cv2.resize(image2, (64, 64))\n",
    "    images2.append(image2)\n",
    "\n",
    "    \n",
    "image_array2 = np.array(images2)\n",
    "image_array2 = image_array2 /255.0\n",
    "\n",
    "#Results\n",
    "predict2 = predict2 * 100\n",
    "predict2 = model2.predict(image_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae2386cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.39596637751156\n",
      "82.79069680471966\n",
      "92.9610992271269\n"
     ]
    }
   ],
   "source": [
    "#Here we work with the metadata\n",
    "\n",
    "#Split the data into correct segments\n",
    "validation = train_data.iloc[0:1000]\n",
    "training = train_data.iloc[1000:]\n",
    "y_train = training['Pawpularity']\n",
    "X_train = training.drop(columns=['Pawpularity', 'Id'])\n",
    "X_test = validation.drop(columns=['Id', 'Pawpularity'])\n",
    "y_test = validation['Pawpularity']\n",
    "\n",
    "\n",
    "#DecisionTreeRegression model\n",
    "model_reg1 = tree.DecisionTreeRegressor(random_state=1)\n",
    "model_reg1.fit(X_train, y_train)\n",
    "results1 = model_reg1.predict(X_test)\n",
    "diff = results1 - y_test\n",
    "percentDiff = (diff / y_test) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "\n",
    "#Calculate the mean of our prediction accuracy\n",
    "mean_tree = np.mean(absPercentDiff)\n",
    "print(mean_tree)\n",
    "\n",
    "#First KNeighborsRegression model\n",
    "model_reg2 = KNeighborsRegressor(n_neighbors = 1)\n",
    "model_reg2.fit(X_train, y_train)\n",
    "results2 = model_reg2.predict(X_test)\n",
    "diff2 = results2 - y_test\n",
    "percentDiff2 = (diff2 / y_test) * 100\n",
    "absPercentDiff2 = np.abs(percentDiff2)\n",
    "\n",
    "#Calculate the mean of our prediction accuracy\n",
    "meanKN_1 = np.mean(absPercentDiff2)\n",
    "print(meanKN_1)\n",
    "\n",
    "#Second KNeighborsRegression model\n",
    "model_reg3 = KNeighborsRegressor(n_neighbors = 15)\n",
    "model_reg3.fit(X_train, y_train)\n",
    "results3 = model_reg3.predict(X_test)\n",
    "diff3 = results3 - y_test\n",
    "percentDiff3 = (diff3 / y_test) * 100\n",
    "absPercentDiff3 = np.abs(percentDiff3)\n",
    "\n",
    "#Calculate the mean of our prediction accuracy\n",
    "meanKN_2 = np.mean(absPercentDiff3)\n",
    "print(meanKN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e95fb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a neural network for metadata analysis\n",
    "\n",
    "def model_for_metadata(dim, regress=False):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee813a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training data\n",
    "(train1, test1) = train_test_split(train_data, test_size=0.25, random_state=42)\n",
    "\n",
    "#Normalize the pawpularity\n",
    "maxPrice_metadata = train1[\"Pawpularity\"].max()\n",
    "trainY_metadata = train1[\"Pawpularity\"] / maxPrice_metadata\n",
    "testY_metadata = test1[\"Pawpularity\"] / maxPrice_metadata\n",
    "\n",
    "#Drop unnecessary colmuns\n",
    "trainX_metadata = train1.drop(columns=['Id', 'Pawpularity'])\n",
    "testX_metadata = test1.drop(columns=['Id', 'Pawpularity'])\n",
    "\n",
    "#Create and compile model\n",
    "model_for_metadata = model_for_metadata(trainX_metadata.shape[1], regress=True)\n",
    "model_for_metadata.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63bbb004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 93.0935 - val_loss: 69.5617\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.6535 - val_loss: 61.0770\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.0941 - val_loss: 58.7368\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 59.0236 - val_loss: 57.7553\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.5506 - val_loss: 57.5685\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.2472 - val_loss: 57.3485\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.9812 - val_loss: 57.2992\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.8741 - val_loss: 57.2319\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.8007 - val_loss: 57.1787\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.7472 - val_loss: 57.1442\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.6710 - val_loss: 57.1396\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.6353 - val_loss: 57.1433\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.5934 - val_loss: 57.0942\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.5357 - val_loss: 57.0429\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.5276 - val_loss: 57.0235\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.4760 - val_loss: 57.0237\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.4518 - val_loss: 57.0293\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.4361 - val_loss: 57.0170\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.4006 - val_loss: 56.9910\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.3948 - val_loss: 56.9988\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.3692 - val_loss: 56.9619\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.3510 - val_loss: 56.9589\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.3320 - val_loss: 56.9314\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.3149 - val_loss: 56.9185\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.3027 - val_loss: 56.9138\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2898 - val_loss: 56.9058\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2764 - val_loss: 56.8941\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2713 - val_loss: 56.8920\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2523 - val_loss: 56.9033\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2435 - val_loss: 56.8802\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2234 - val_loss: 56.8668\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.2056 - val_loss: 56.8282\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2140 - val_loss: 56.8295\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.1847 - val_loss: 56.8409\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1800 - val_loss: 56.8537\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1671 - val_loss: 56.8339\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1645 - val_loss: 56.8181\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1441 - val_loss: 56.8809\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1353 - val_loss: 56.8440\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1137 - val_loss: 56.8181\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1127 - val_loss: 56.8242\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.1013 - val_loss: 56.8191\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.0936 - val_loss: 56.8146\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 57.0776 - val_loss: 56.8324\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.0788 - val_loss: 56.8203\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 57.0679 - val_loss: 56.8302\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 57.0693 - val_loss: 56.8209\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 57.0461 - val_loss: 56.8135\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 57.0593 - val_loss: 56.8238\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 57.0390 - val_loss: 56.8230\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 57.0359 - val_loss: 56.7922\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 57.0836 - val_loss: 56.7928\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 57.0232 - val_loss: 56.8656\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 57.0532 - val_loss: 56.8722\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 57.0309 - val_loss: 56.8434\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 57.0111 - val_loss: 56.8386\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 57.0014 - val_loss: 56.8325\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 56.9927 - val_loss: 56.8462\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 57.0060 - val_loss: 56.8533\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.9826 - val_loss: 56.8400\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.9813 - val_loss: 56.8440\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.9736 - val_loss: 56.8766\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.0106 - val_loss: 56.9054\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.9910 - val_loss: 56.8548\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.9689 - val_loss: 56.8384\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 56.9620 - val_loss: 56.8278\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 56.9534 - val_loss: 56.8375\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.9565 - val_loss: 56.8544\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.9440 - val_loss: 56.8582\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.9466 - val_loss: 56.8658\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 56.9289 - val_loss: 56.8445\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.9194 - val_loss: 56.8350\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.9212 - val_loss: 56.8271\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.9189 - val_loss: 56.8344\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.9072 - val_loss: 56.8306\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.9061 - val_loss: 56.8336\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8961 - val_loss: 56.8406\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8947 - val_loss: 56.8473\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8956 - val_loss: 56.8561\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.9039 - val_loss: 56.8584\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.9032 - val_loss: 56.8832\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8900 - val_loss: 56.8534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8922 - val_loss: 56.8241\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 56.8834 - val_loss: 56.8340\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 56.8687 - val_loss: 56.8202\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8600 - val_loss: 56.8117\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8587 - val_loss: 56.8063\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8509 - val_loss: 56.8013\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8456 - val_loss: 56.7907\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8424 - val_loss: 56.7916\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8398 - val_loss: 56.7963\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8412 - val_loss: 56.8025\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8371 - val_loss: 56.8009\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 56.8330 - val_loss: 56.8021\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8337 - val_loss: 56.7991\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8195 - val_loss: 56.7941\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8449 - val_loss: 56.8061\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8205 - val_loss: 56.8037\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 56.8158 - val_loss: 56.8136\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 56.8252 - val_loss: 56.8006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2752ccffaf0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model_for_metadata.fit(x=trainX_metadata, y=trainY_metadata, \n",
    "    validation_data=(testX_metadata, testY_metadata),\n",
    "    epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08e8df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.800626150214576\n"
     ]
    }
   ],
   "source": [
    "#Analyze results\n",
    "\n",
    "#Predict scores\n",
    "preds_for_metadata = model_for_metadata.predict(testX_metadata)\n",
    "\n",
    "#Calculate the differences between results and the real values\n",
    "diff_for_metadata = preds_for_metadata.flatten() - testY_metadata\n",
    "percentDiff_for_metadata = (diff_for_metadata / testY_metadata) * 100\n",
    "absPercentDiff_for_metadata = np.abs(percentDiff_for_metadata)\n",
    "\n",
    "#Calculate the mean of our prediction accuracy\n",
    "mean_metadata = np.mean(absPercentDiff_for_metadata)\n",
    "print(mean_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394cf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
